# 220423 Study Group : ML

# 1. 머신러닝이란

예) 서울 집값 맞추는 프로그램에서

- 범죄율, 번화가까지 거리, 등등등의 많은 데이터 간 상관관계를 컴퓨터가 알아서 때려맞추도록 하는 것
- 컴퓨터가 알아서 때려맞추는 프로그램을 **모델(Model)**이라고 함.
- 컴퓨터가 아무 값이나 넣고 계산 → 실제 계산결과를 바탕로 **오차를 수정** → 반복 → 얼추 오차를 다 줄이면 **학습(Train)** 종료.
- 좋은 모델을 평가하는 기준 : 학습할 때 사용한 데이터가 아닌, 새 데이터를 기준으로 평가. 머신러닝은 미래의 데이터(모르는 데이터)를 잘 맞추는 것이 중요하기 때문.
    - 가지고 있는 데이터의 일부를 테스트용 데이터로 빼두고 훈련시킴. 훈련 후 테스트용 데이터(기계가 학습하지 않은 데이터)로 테스트함.
- 회귀? : 집값이 얼마인지 값이 나오는 것 ↔ **분류**? : 개인지 고양이인지 YES/NO가 나오는 것.

# 2. 미분(derivative)

- 순간 변화율(자동차의 거리/시간을 구하는 그래프에서 순간 기울기)
- **ML에서 오차를 줄이는 학습**을 할 때 사용
    - 아무 값이나 집어넣고 실제 데이터와 비교한 오차를 확인.
    - 평균 제곱 오차(MSE, Mean Squared Error) = 오차^2/전체 갯수
        - 제곱하면 음수가 양수가 되므로 굳이 제곱. 하나도 못 맞췄을 때 오차가 0이 되는 참사 방지. 절댓값을 사용할 수도 있음.

# 3. **선형회귀(Linear Regression)**

1. 변수를 바꿔가며 평균 제곱 오차를 계속 변함.
2. 미분을 통해 기울기를 구해서 변수의 값을 추가 조절.
3. 이를 반복하여 오차가 최소가 되는(기울기가 0이 되는) 값을 구하는 것.
- 그려지는 그래프가 1차함수(선형)이 아니라 2차함수(곡선)이면 2차회귀(로지스틱회귀)
- 데이터 시각화가 중요한 이유 : 선형회귀/로지스틱회귀 중 무엇을 할지는 사람이 고름.
- 변수가 늘어나서(범죄율, 교사비율, 번화가까지 거리, 외국인 비율, 일산화탄소 농도, etc) 실제 데이터(집값)과 비교 : n차원 선형회귀

# 4. 응용

- 결정 트리(Decision Tree) 알고리즘 : 분류에 사용, 데이터를 나타낸 그래프에서 값을 깔끔하게 나누는 축을 찾음. 축을 기준으로 새 데이터가 무엇인지 분류, 과적합이 잘 발생하므로 축의 숫자를 제한함.
- SVM(Support Vector Machine) : 분류에 사용, 데이터를 나타내는 그래프에서 값을 깔끔하게 나누는 선(각 값에서 거리[마진, 공간]가 최대한 먼 선)을 찾음. 향후에 나타나는 데이터를 대비하는 알고리즘.
- 과적합(Overfitting) : Train Set(학습에 사용되는 데이터)는 다 맞추는데 지나치게 복잡해짐 → 새로 들어온 데이터를 맞추지 못함. → Ridge/Lasso 규제로 변화율(기울기)를 규제함.
    - 정확도 0.99 등이 나오기 때문에 틀렸는지 눈치채기 힘듬. 시장에 나가서 터짐.
- 과소적합(Underfitting) : 학습횟수가 적거나, 데이터셋이 적거나, 모델을 잘못 선택(복잡한 데이터셋에서 적절하지 않게 선형회귀 등을 고름)하여, 부적합한 모델이 만들어지는 것.
    - 정확도 0.34 등이 나와서 틀렸는지 쉽게 눈치챔. 보완 가능.